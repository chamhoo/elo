{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, StratifiedKFold, cross_val_score\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/root/data/train.csv')\n",
    "df_test = pd.read_csv('/root/data/test.csv')\n",
    "df_hist_trans = pd.read_csv('/root/data/historical_transactions.csv')\n",
    "df_new_merchant_trans = pd.read_csv('/root/data/new_merchant_transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_hist_trans,df_new_merchant_trans]:\n",
    "    df['category_2'].fillna(1.0,inplace=True)\n",
    "    df['category_3'].fillna('A',inplace=True)\n",
    "    df['merchant_id'].fillna('M_ID_00a6ca8a8a',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_columns(name,aggs):\n",
    "    return [name + '_' + k + '_' + agg for k in aggs.keys() for agg in aggs[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_hist_trans,df_new_merchant_trans]:\n",
    "    df['purchase_date'] = pd.to_datetime(df['purchase_date'])\n",
    "    df['year'] = df['purchase_date'].dt.year\n",
    "    df['weekofyear'] = df['purchase_date'].dt.weekofyear\n",
    "    df['month'] = df['purchase_date'].dt.month\n",
    "    df['dayofweek'] = df['purchase_date'].dt.dayofweek\n",
    "    df['weekend'] = (df.purchase_date.dt.weekday >=5).astype(int)\n",
    "    df['hour'] = df['purchase_date'].dt.hour\n",
    "    df['authorized_flag'] = df['authorized_flag'].map({'Y':1, 'N':0})\n",
    "    df['category_1'] = df['category_1'].map({'Y':1, 'N':0}) \n",
    "    #https://www.kaggle.com/c/elo-merchant-category-recommendation/discussion/73244\n",
    "    df['month_diff'] = ((datetime.datetime.today() - df['purchase_date']).dt.days)//30\n",
    "    df['month_diff'] += df['month_lag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggs = {}\n",
    "for col in ['month','hour','weekofyear','dayofweek','year','subsector_id','merchant_id','merchant_category_id']:\n",
    "    aggs[col] = ['nunique']\n",
    "\n",
    "aggs['purchase_amount'] = ['sum','max','min','mean','var']\n",
    "aggs['installments'] = ['sum','max','min','mean','var']\n",
    "aggs['purchase_date'] = ['max','min']\n",
    "aggs['month_lag'] = ['max','min','mean','var']\n",
    "aggs['month_diff'] = ['mean']\n",
    "aggs['authorized_flag'] = ['sum', 'mean']\n",
    "aggs['weekend'] = ['sum', 'mean']\n",
    "aggs['category_1'] = ['sum', 'mean']\n",
    "aggs['card_id'] = ['size']\n",
    "\n",
    "for col in ['category_2','category_3']:\n",
    "    df_hist_trans[col+'_mean'] = df_hist_trans.groupby([col])['purchase_amount'].transform('mean')\n",
    "    aggs[col+'_mean'] = ['mean']    \n",
    "\n",
    "new_columns = get_new_columns('hist',aggs)\n",
    "df_hist_trans_group = df_hist_trans.groupby('card_id').agg(aggs)\n",
    "df_hist_trans_group.columns = new_columns\n",
    "df_hist_trans_group.reset_index(drop=False,inplace=True)\n",
    "df_hist_trans_group['hist_purchase_date_diff'] = (df_hist_trans_group['hist_purchase_date_max'] - df_hist_trans_group['hist_purchase_date_min']).dt.days\n",
    "df_hist_trans_group['hist_purchase_date_average'] = df_hist_trans_group['hist_purchase_date_diff']/df_hist_trans_group['hist_card_id_size']\n",
    "df_hist_trans_group['hist_purchase_date_uptonow'] = (datetime.datetime.today() - df_hist_trans_group['hist_purchase_date_max']).dt.days\n",
    "df_train = df_train.merge(df_hist_trans_group,on='card_id',how='left')\n",
    "df_test = df_test.merge(df_hist_trans_group,on='card_id',how='left')\n",
    "del df_hist_trans_group;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "aggs = {}\n",
    "for col in ['month','hour','weekofyear','dayofweek','year','subsector_id','merchant_id','merchant_category_id']:\n",
    "    aggs[col] = ['nunique']\n",
    "aggs['purchase_amount'] = ['sum','max','min','mean','var']\n",
    "aggs['installments'] = ['sum','max','min','mean','var']\n",
    "aggs['purchase_date'] = ['max','min']\n",
    "aggs['month_lag'] = ['max','min','mean','var']\n",
    "aggs['month_diff'] = ['mean']\n",
    "aggs['weekend'] = ['sum', 'mean']\n",
    "aggs['category_1'] = ['sum', 'mean']\n",
    "aggs['card_id'] = ['size']\n",
    "\n",
    "for col in ['category_2','category_3']:\n",
    "    df_new_merchant_trans[col+'_mean'] = df_new_merchant_trans.groupby([col])['purchase_amount'].transform('mean')\n",
    "    aggs[col+'_mean'] = ['mean']\n",
    "    \n",
    "new_columns = get_new_columns('new_hist',aggs)\n",
    "df_hist_trans_group = df_new_merchant_trans.groupby('card_id').agg(aggs)\n",
    "df_hist_trans_group.columns = new_columns\n",
    "df_hist_trans_group.reset_index(drop=False,inplace=True)\n",
    "df_hist_trans_group['new_hist_purchase_date_diff'] = (df_hist_trans_group['new_hist_purchase_date_max'] - df_hist_trans_group['new_hist_purchase_date_min']).dt.days\n",
    "df_hist_trans_group['new_hist_purchase_date_average'] = df_hist_trans_group['new_hist_purchase_date_diff']/df_hist_trans_group['new_hist_card_id_size']\n",
    "df_hist_trans_group['new_hist_purchase_date_uptonow'] = (datetime.datetime.today() - df_hist_trans_group['new_hist_purchase_date_max']).dt.days\n",
    "df_train = df_train.merge(df_hist_trans_group,on='card_id',how='left')\n",
    "df_test = df_test.merge(df_hist_trans_group,on='card_id',how='left')\n",
    "del df_hist_trans_group;gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "      <th>hist_month_nunique</th>\n",
       "      <th>hist_hour_nunique</th>\n",
       "      <th>hist_weekofyear_nunique</th>\n",
       "      <th>hist_dayofweek_nunique</th>\n",
       "      <th>...</th>\n",
       "      <th>new_hist_weekend_sum</th>\n",
       "      <th>new_hist_weekend_mean</th>\n",
       "      <th>new_hist_category_1_sum</th>\n",
       "      <th>new_hist_category_1_mean</th>\n",
       "      <th>new_hist_card_id_size</th>\n",
       "      <th>new_hist_category_2_mean_mean</th>\n",
       "      <th>new_hist_category_3_mean_mean</th>\n",
       "      <th>new_hist_purchase_date_diff</th>\n",
       "      <th>new_hist_purchase_date_average</th>\n",
       "      <th>new_hist_purchase_date_uptonow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06</td>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-0.550160</td>\n",
       "      <td>-0.592993</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.347826</td>\n",
       "      <td>249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01</td>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.550160</td>\n",
       "      <td>-0.606486</td>\n",
       "      <td>56.0</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08</td>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.549015</td>\n",
       "      <td>-0.592993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09</td>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.556518</td>\n",
       "      <td>-0.604559</td>\n",
       "      <td>41.0</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11</td>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-0.555446</td>\n",
       "      <td>-0.588217</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_active_month          card_id  feature_1  feature_2  feature_3  \\\n",
       "0            2017-06  C_ID_92a2005557          5          2          1   \n",
       "1            2017-01  C_ID_3d0044924f          4          1          0   \n",
       "2            2016-08  C_ID_d639edf6cd          2          2          0   \n",
       "3            2017-09  C_ID_186d6a6901          4          3          0   \n",
       "4            2017-11  C_ID_cdbd2c0db2          1          3          0   \n",
       "\n",
       "     target  hist_month_nunique  hist_hour_nunique  hist_weekofyear_nunique  \\\n",
       "0 -0.820283                   9                 23                       35   \n",
       "1  0.392913                  12                 24                       50   \n",
       "2  0.688056                  10                 14                       22   \n",
       "3  0.142495                   6                 16                       20   \n",
       "4 -0.159749                   4                 22                       17   \n",
       "\n",
       "   hist_dayofweek_nunique               ...                \\\n",
       "0                       7               ...                 \n",
       "1                       7               ...                 \n",
       "2                       7               ...                 \n",
       "3                       7               ...                 \n",
       "4                       7               ...                 \n",
       "\n",
       "   new_hist_weekend_sum  new_hist_weekend_mean  new_hist_category_1_sum  \\\n",
       "0                   6.0               0.260870                      0.0   \n",
       "1                   0.0               0.000000                      0.0   \n",
       "2                   1.0               1.000000                      0.0   \n",
       "3                   3.0               0.428571                      1.0   \n",
       "4                  12.0               0.333333                      2.0   \n",
       "\n",
       "   new_hist_category_1_mean  new_hist_card_id_size  \\\n",
       "0                  0.000000                   23.0   \n",
       "1                  0.000000                    6.0   \n",
       "2                  0.000000                    1.0   \n",
       "3                  0.142857                    7.0   \n",
       "4                  0.055556                   36.0   \n",
       "\n",
       "   new_hist_category_2_mean_mean  new_hist_category_3_mean_mean  \\\n",
       "0                      -0.550160                      -0.592993   \n",
       "1                      -0.550160                      -0.606486   \n",
       "2                      -0.549015                      -0.592993   \n",
       "3                      -0.556518                      -0.604559   \n",
       "4                      -0.555446                      -0.588217   \n",
       "\n",
       "   new_hist_purchase_date_diff  new_hist_purchase_date_average  \\\n",
       "0                         54.0                        2.347826   \n",
       "1                         56.0                        9.333333   \n",
       "2                          0.0                        0.000000   \n",
       "3                         41.0                        5.857143   \n",
       "4                         57.0                        1.583333   \n",
       "\n",
       "   new_hist_purchase_date_uptonow  \n",
       "0                           249.0  \n",
       "1                           279.0  \n",
       "2                           250.0  \n",
       "3                           260.0  \n",
       "4                           250.0  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_hist_trans;gc.collect()\n",
    "del df_new_merchant_trans;gc.collect()\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199710\n",
       "1      2207\n",
       "Name: outliers, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['outliers'] = 0\n",
    "df_train.loc[df_train['target'] < -30, 'outliers'] = 1\n",
    "df_train['outliers'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_train,df_test]:\n",
    "    df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n",
    "    df['dayofweek'] = df['first_active_month'].dt.dayofweek\n",
    "    df['weekofyear'] = df['first_active_month'].dt.weekofyear\n",
    "    df['month'] = df['first_active_month'].dt.month\n",
    "    df['elapsed_time'] = (datetime.datetime.today() - df['first_active_month']).dt.days\n",
    "    df['hist_first_buy'] = (df['hist_purchase_date_min'] - df['first_active_month']).dt.days\n",
    "    df['new_hist_first_buy'] = (df['new_hist_purchase_date_min'] - df['first_active_month']).dt.days\n",
    "    for f in ['hist_purchase_date_max','hist_purchase_date_min','new_hist_purchase_date_max',\\\n",
    "                     'new_hist_purchase_date_min']:\n",
    "        df[f] = df[f].astype(np.int64) * 1e-9\n",
    "    df['card_id_total'] = df['new_hist_card_id_size']+df['hist_card_id_size']\n",
    "    df['purchase_amount_total'] = df['new_hist_purchase_amount_sum']+df['hist_purchase_amount_sum']\n",
    "\n",
    "for f in ['feature_1','feature_2','feature_3']:                        \n",
    "    order_label = df_train.groupby([f])['outliers'].mean()\n",
    "    df_train[f] = df_train[f].map(order_label)\n",
    "    df_test[f] = df_test[f].map(order_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_columns = [c for c in df_train.columns if c not in ['card_id', 'first_active_month','target','outliers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_cv(param, data, cv):\n",
    "    score = lgb.cv( \n",
    "        param, \n",
    "        data, \n",
    "        nfold=cv,\n",
    "        stratified=False, \n",
    "        shuffle=True,\n",
    "        metrics='rmse',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False, \n",
    "        show_stdv=False)\n",
    "    return score['rmse-mean'][-1]\n",
    "\n",
    "\n",
    "def hyperopt_train_test(params):\n",
    "    global df_train\n",
    "    \n",
    "    param = {\n",
    "        'objective':'regression',\n",
    "        \"boosting\": \"gbdt\",\n",
    "    }\n",
    "    param['max_depth'] = int(params['max_depth'])\n",
    "    param['num_leaves'] = int(params['num_leaves'])\n",
    "    param['min_data_in_leaf'] = int(params['min_data_in_leaf'])\n",
    "    param['reg_alpha'] = params['reg_alpha']\n",
    "    param['reg_lambda'] = params['reg_lambda']\n",
    "    param['feature_fraction'] = params['feature_fraction']\n",
    "    \n",
    "    df_train_columns = [c for c in df_train.columns if c not in ['card_id', 'first_active_month','target','outliers']]\n",
    "    data_train = lgb.Dataset(df_train[df_train_columns], label=df_train['target'])\n",
    "    return regression_cv(param, data_train, cv=5)\n",
    "\n",
    "\n",
    "def f(params):\n",
    "    global best\n",
    "    score = hyperopt_train_test(params)\n",
    "    if -score > best:\n",
    "        best = -score\n",
    "        print('new best:', -best, params)\n",
    "    return {'loss': score, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best: 3.659868101823613 {'feature_fraction': 0.7801719990248783, 'max_depth': 12.0, 'min_data_in_leaf': 308.0, 'num_leaves': 79.0, 'reg_alpha': 0.002616237891337081, 'reg_lambda': 0.44173487967164776}\n",
      "new best: 3.658105651811879 {'feature_fraction': 0.9903078304451878, 'max_depth': 7.0, 'min_data_in_leaf': 226.0, 'num_leaves': 178.0, 'reg_alpha': 0.3357829881806267, 'reg_lambda': 0.2943760133337211}\n",
      "new best: 3.6576589270306386 {'feature_fraction': 0.8186974015821651, 'max_depth': 6.0, 'min_data_in_leaf': 294.0, 'num_leaves': 195.0, 'reg_alpha': 0.031306762618277195, 'reg_lambda': 0.2917369661750133}\n",
      "new best: 3.657123425067369 {'feature_fraction': 0.9563058211301799, 'max_depth': 6.0, 'min_data_in_leaf': 293.0, 'num_leaves': 277.0, 'reg_alpha': 0.14544787152042116, 'reg_lambda': 0.1801851271059528}\n",
      "new best: 3.6570764530426474 {'feature_fraction': 0.8854330611486116, 'max_depth': 7.0, 'min_data_in_leaf': 309.0, 'num_leaves': 206.0, 'reg_alpha': 0.022647609388158026, 'reg_lambda': 0.14995490342255752}\n",
      "new best: 3.656758549564646 {'feature_fraction': 0.7454526265245789, 'max_depth': 7.0, 'min_data_in_leaf': 292.0, 'num_leaves': 250.0, 'reg_alpha': 0.06256726294587879, 'reg_lambda': 0.20774780856749556}\n",
      "new best: 3.656445402773759 {'feature_fraction': 0.6702657035034688, 'max_depth': 6.0, 'min_data_in_leaf': 214.0, 'num_leaves': 319.0, 'reg_alpha': 0.16798402179084337, 'reg_lambda': 0.39996753860496637}\n",
      "new best: 3.6551237413742768 {'feature_fraction': 0.5973884630418472, 'max_depth': 7.0, 'min_data_in_leaf': 235.0, 'num_leaves': 272.0, 'reg_alpha': 0.1453867929507931, 'reg_lambda': 0.36757830891797294}\n",
      "new best: 3.655064946046229 {'feature_fraction': 0.5775349282300533, 'max_depth': 6.0, 'min_data_in_leaf': 350.0, 'num_leaves': 243.0, 'reg_alpha': 0.08335604635874802, 'reg_lambda': 0.14749148707496232}\n",
      "best:\n",
      "{'feature_fraction': 0.5775349282300533, 'max_depth': 6.0, 'min_data_in_leaf': 350.0, 'num_leaves': 243.0, 'reg_alpha': 0.08335604635874802, 'reg_lambda': 0.14749148707496232}\n"
     ]
    }
   ],
   "source": [
    "space4rf = {\n",
    "    'max_depth': hp.quniform('max_depth', 5, 13, 1),\n",
    "    'num_leaves':hp.quniform('num_leaves', 10, 350, 1),\n",
    "    'min_data_in_leaf':hp.quniform('min_data_in_leaf', 10, 350, 1),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0, 0.5),   \n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0, 0.5),\n",
    "    'feature_fraction' : hp.uniform('feature_fraction', 0.5, 1)}\n",
    "\n",
    "best = -15\n",
    "trials = Trials()\n",
    "best = fmin(f, space4rf, algo=tpe.suggest, max_evals=900, trials=trials)\n",
    "\n",
    "print('best:')\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's rmse: 3.69047\tvalid_1's rmse: 3.69715\n",
      "[2000]\ttraining's rmse: 3.64254\tvalid_1's rmse: 3.65733\n",
      "[3000]\ttraining's rmse: 3.61914\tvalid_1's rmse: 3.64188\n",
      "[4000]\ttraining's rmse: 3.60414\tvalid_1's rmse: 3.63665\n",
      "[5000]\ttraining's rmse: 3.5936\tvalid_1's rmse: 3.63315\n",
      "[6000]\ttraining's rmse: 3.58409\tvalid_1's rmse: 3.63119\n",
      "[7000]\ttraining's rmse: 3.57718\tvalid_1's rmse: 3.62971\n",
      "[8000]\ttraining's rmse: 3.57079\tvalid_1's rmse: 3.6285\n",
      "[9000]\ttraining's rmse: 3.56477\tvalid_1's rmse: 3.62748\n",
      "[10000]\ttraining's rmse: 3.5586\tvalid_1's rmse: 3.62673\n",
      "[11000]\ttraining's rmse: 3.55243\tvalid_1's rmse: 3.62611\n",
      "[12000]\ttraining's rmse: 3.54686\tvalid_1's rmse: 3.6256\n",
      "[13000]\ttraining's rmse: 3.54119\tvalid_1's rmse: 3.62528\n",
      "[14000]\ttraining's rmse: 3.53565\tvalid_1's rmse: 3.62496\n",
      "[15000]\ttraining's rmse: 3.52986\tvalid_1's rmse: 3.62487\n",
      "[16000]\ttraining's rmse: 3.52443\tvalid_1's rmse: 3.62496\n",
      "Early stopping, best iteration is:\n",
      "[15449]\ttraining's rmse: 3.52735\tvalid_1's rmse: 3.62483\n",
      "fold 1\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's rmse: 3.68945\tvalid_1's rmse: 3.71093\n",
      "[2000]\ttraining's rmse: 3.63943\tvalid_1's rmse: 3.67959\n",
      "[3000]\ttraining's rmse: 3.61491\tvalid_1's rmse: 3.67021\n",
      "[4000]\ttraining's rmse: 3.60012\tvalid_1's rmse: 3.66646\n",
      "[5000]\ttraining's rmse: 3.59005\tvalid_1's rmse: 3.66432\n",
      "[6000]\ttraining's rmse: 3.58159\tvalid_1's rmse: 3.66301\n",
      "[7000]\ttraining's rmse: 3.57321\tvalid_1's rmse: 3.66233\n",
      "[8000]\ttraining's rmse: 3.56605\tvalid_1's rmse: 3.66244\n",
      "Early stopping, best iteration is:\n",
      "[7227]\ttraining's rmse: 3.57154\tvalid_1's rmse: 3.6623\n",
      "fold 2\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's rmse: 3.68713\tvalid_1's rmse: 3.71594\n",
      "[2000]\ttraining's rmse: 3.63769\tvalid_1's rmse: 3.68626\n",
      "[3000]\ttraining's rmse: 3.61292\tvalid_1's rmse: 3.67683\n",
      "[4000]\ttraining's rmse: 3.59857\tvalid_1's rmse: 3.67316\n",
      "[5000]\ttraining's rmse: 3.58773\tvalid_1's rmse: 3.67007\n",
      "[6000]\ttraining's rmse: 3.57949\tvalid_1's rmse: 3.66792\n",
      "[7000]\ttraining's rmse: 3.5723\tvalid_1's rmse: 3.66649\n",
      "[8000]\ttraining's rmse: 3.56602\tvalid_1's rmse: 3.66534\n",
      "[9000]\ttraining's rmse: 3.55998\tvalid_1's rmse: 3.6646\n",
      "[10000]\ttraining's rmse: 3.55438\tvalid_1's rmse: 3.66412\n",
      "[11000]\ttraining's rmse: 3.54874\tvalid_1's rmse: 3.66382\n",
      "[12000]\ttraining's rmse: 3.54338\tvalid_1's rmse: 3.66371\n",
      "[13000]\ttraining's rmse: 3.53837\tvalid_1's rmse: 3.66352\n",
      "[14000]\ttraining's rmse: 3.53302\tvalid_1's rmse: 3.66333\n",
      "Early stopping, best iteration is:\n",
      "[13961]\ttraining's rmse: 3.53322\tvalid_1's rmse: 3.66332\n",
      "fold 3\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's rmse: 3.68763\tvalid_1's rmse: 3.72321\n",
      "[2000]\ttraining's rmse: 3.63691\tvalid_1's rmse: 3.69304\n",
      "[3000]\ttraining's rmse: 3.61241\tvalid_1's rmse: 3.68403\n",
      "[4000]\ttraining's rmse: 3.59748\tvalid_1's rmse: 3.68043\n",
      "[5000]\ttraining's rmse: 3.58714\tvalid_1's rmse: 3.67876\n",
      "[6000]\ttraining's rmse: 3.57798\tvalid_1's rmse: 3.67715\n",
      "[7000]\ttraining's rmse: 3.57034\tvalid_1's rmse: 3.67618\n",
      "[8000]\ttraining's rmse: 3.56372\tvalid_1's rmse: 3.67549\n",
      "[9000]\ttraining's rmse: 3.55762\tvalid_1's rmse: 3.67513\n",
      "[10000]\ttraining's rmse: 3.55165\tvalid_1's rmse: 3.67478\n",
      "[11000]\ttraining's rmse: 3.54572\tvalid_1's rmse: 3.67457\n",
      "[12000]\ttraining's rmse: 3.53967\tvalid_1's rmse: 3.67455\n",
      "Early stopping, best iteration is:\n",
      "[11623]\ttraining's rmse: 3.54193\tvalid_1's rmse: 3.67451\n",
      "fold 4\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's rmse: 3.68775\tvalid_1's rmse: 3.71888\n",
      "[2000]\ttraining's rmse: 3.63796\tvalid_1's rmse: 3.68632\n",
      "[3000]\ttraining's rmse: 3.61333\tvalid_1's rmse: 3.67423\n",
      "[4000]\ttraining's rmse: 3.59902\tvalid_1's rmse: 3.66813\n",
      "[5000]\ttraining's rmse: 3.58891\tvalid_1's rmse: 3.66403\n",
      "[6000]\ttraining's rmse: 3.58014\tvalid_1's rmse: 3.66192\n",
      "[7000]\ttraining's rmse: 3.57245\tvalid_1's rmse: 3.66049\n",
      "[8000]\ttraining's rmse: 3.5657\tvalid_1's rmse: 3.65942\n",
      "[9000]\ttraining's rmse: 3.55951\tvalid_1's rmse: 3.6587\n",
      "[10000]\ttraining's rmse: 3.55403\tvalid_1's rmse: 3.65811\n",
      "[11000]\ttraining's rmse: 3.54827\tvalid_1's rmse: 3.65747\n",
      "[12000]\ttraining's rmse: 3.54224\tvalid_1's rmse: 3.65714\n",
      "[13000]\ttraining's rmse: 3.5371\tvalid_1's rmse: 3.65691\n",
      "[14000]\ttraining's rmse: 3.53244\tvalid_1's rmse: 3.65672\n",
      "[15000]\ttraining's rmse: 3.52666\tvalid_1's rmse: 3.65665\n",
      "Early stopping, best iteration is:\n",
      "[14984]\ttraining's rmse: 3.52677\tvalid_1's rmse: 3.65664\n",
      "fold 5\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's rmse: 3.68755\tvalid_1's rmse: 3.71924\n",
      "[2000]\ttraining's rmse: 3.63856\tvalid_1's rmse: 3.69035\n",
      "[3000]\ttraining's rmse: 3.61472\tvalid_1's rmse: 3.67916\n",
      "[4000]\ttraining's rmse: 3.59992\tvalid_1's rmse: 3.67403\n",
      "[5000]\ttraining's rmse: 3.58844\tvalid_1's rmse: 3.6717\n",
      "[6000]\ttraining's rmse: 3.57942\tvalid_1's rmse: 3.67012\n",
      "[7000]\ttraining's rmse: 3.5721\tvalid_1's rmse: 3.66906\n",
      "[8000]\ttraining's rmse: 3.5654\tvalid_1's rmse: 3.66834\n",
      "[9000]\ttraining's rmse: 3.55886\tvalid_1's rmse: 3.66815\n",
      "[10000]\ttraining's rmse: 3.55278\tvalid_1's rmse: 3.66791\n",
      "[11000]\ttraining's rmse: 3.54674\tvalid_1's rmse: 3.66787\n",
      "[12000]\ttraining's rmse: 3.54073\tvalid_1's rmse: 3.66771\n",
      "[13000]\ttraining's rmse: 3.53519\tvalid_1's rmse: 3.66742\n",
      "[14000]\ttraining's rmse: 3.52934\tvalid_1's rmse: 3.66748\n",
      "Early stopping, best iteration is:\n",
      "[13350]\ttraining's rmse: 3.5333\tvalid_1's rmse: 3.66735\n",
      "fold 6\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's rmse: 3.68875\tvalid_1's rmse: 3.70963\n",
      "[2000]\ttraining's rmse: 3.63899\tvalid_1's rmse: 3.67894\n",
      "[3000]\ttraining's rmse: 3.61433\tvalid_1's rmse: 3.66753\n",
      "[4000]\ttraining's rmse: 3.59973\tvalid_1's rmse: 3.66224\n",
      "[5000]\ttraining's rmse: 3.58952\tvalid_1's rmse: 3.65897\n",
      "[6000]\ttraining's rmse: 3.58094\tvalid_1's rmse: 3.65683\n",
      "[7000]\ttraining's rmse: 3.57337\tvalid_1's rmse: 3.65523\n",
      "[8000]\ttraining's rmse: 3.5662\tvalid_1's rmse: 3.65457\n",
      "[9000]\ttraining's rmse: 3.55954\tvalid_1's rmse: 3.6541\n",
      "[10000]\ttraining's rmse: 3.5532\tvalid_1's rmse: 3.65391\n",
      "[11000]\ttraining's rmse: 3.54672\tvalid_1's rmse: 3.654\n",
      "Early stopping, best iteration is:\n",
      "[10381]\ttraining's rmse: 3.55083\tvalid_1's rmse: 3.65385\n",
      "fold 7\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's rmse: 3.69194\tvalid_1's rmse: 3.69359\n",
      "[2000]\ttraining's rmse: 3.64272\tvalid_1's rmse: 3.65293\n",
      "[3000]\ttraining's rmse: 3.61894\tvalid_1's rmse: 3.63758\n",
      "[4000]\ttraining's rmse: 3.60465\tvalid_1's rmse: 3.63089\n",
      "[5000]\ttraining's rmse: 3.59476\tvalid_1's rmse: 3.62678\n",
      "[6000]\ttraining's rmse: 3.58609\tvalid_1's rmse: 3.62412\n",
      "[7000]\ttraining's rmse: 3.57907\tvalid_1's rmse: 3.62254\n",
      "[8000]\ttraining's rmse: 3.5726\tvalid_1's rmse: 3.62133\n",
      "[9000]\ttraining's rmse: 3.56618\tvalid_1's rmse: 3.62039\n",
      "[10000]\ttraining's rmse: 3.56004\tvalid_1's rmse: 3.61936\n",
      "[11000]\ttraining's rmse: 3.554\tvalid_1's rmse: 3.61836\n",
      "[12000]\ttraining's rmse: 3.54858\tvalid_1's rmse: 3.61765\n",
      "[13000]\ttraining's rmse: 3.54352\tvalid_1's rmse: 3.61725\n",
      "[14000]\ttraining's rmse: 3.53856\tvalid_1's rmse: 3.61709\n",
      "[15000]\ttraining's rmse: 3.53338\tvalid_1's rmse: 3.61703\n",
      "[16000]\ttraining's rmse: 3.52839\tvalid_1's rmse: 3.61677\n",
      "[17000]\ttraining's rmse: 3.52338\tvalid_1's rmse: 3.61671\n",
      "[18000]\ttraining's rmse: 3.51813\tvalid_1's rmse: 3.61655\n",
      "[19000]\ttraining's rmse: 3.51264\tvalid_1's rmse: 3.61624\n",
      "[20000]\ttraining's rmse: 3.50757\tvalid_1's rmse: 3.61595\n",
      "[21000]\ttraining's rmse: 3.5028\tvalid_1's rmse: 3.61585\n",
      "[22000]\ttraining's rmse: 3.49828\tvalid_1's rmse: 3.61565\n",
      "[23000]\ttraining's rmse: 3.49355\tvalid_1's rmse: 3.6154\n",
      "[24000]\ttraining's rmse: 3.48885\tvalid_1's rmse: 3.61533\n",
      "[25000]\ttraining's rmse: 3.48399\tvalid_1's rmse: 3.61518\n",
      "[26000]\ttraining's rmse: 3.47953\tvalid_1's rmse: 3.61507\n",
      "[27000]\ttraining's rmse: 3.47492\tvalid_1's rmse: 3.61508\n",
      "Early stopping, best iteration is:\n",
      "[26041]\ttraining's rmse: 3.47933\tvalid_1's rmse: 3.61506\n",
      "fold 8\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's rmse: 3.69013\tvalid_1's rmse: 3.69083\n",
      "[2000]\ttraining's rmse: 3.6403\tvalid_1's rmse: 3.65893\n",
      "[3000]\ttraining's rmse: 3.61612\tvalid_1's rmse: 3.649\n",
      "[4000]\ttraining's rmse: 3.60142\tvalid_1's rmse: 3.64523\n",
      "[5000]\ttraining's rmse: 3.59117\tvalid_1's rmse: 3.64333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6000]\ttraining's rmse: 3.58271\tvalid_1's rmse: 3.64267\n",
      "[7000]\ttraining's rmse: 3.57476\tvalid_1's rmse: 3.64227\n",
      "[8000]\ttraining's rmse: 3.56737\tvalid_1's rmse: 3.64257\n",
      "Early stopping, best iteration is:\n",
      "[7070]\ttraining's rmse: 3.57424\tvalid_1's rmse: 3.64227\n",
      "fold 9\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's rmse: 3.68837\tvalid_1's rmse: 3.70526\n",
      "[2000]\ttraining's rmse: 3.63881\tvalid_1's rmse: 3.66927\n",
      "[3000]\ttraining's rmse: 3.61408\tvalid_1's rmse: 3.65565\n",
      "[4000]\ttraining's rmse: 3.59859\tvalid_1's rmse: 3.65043\n",
      "[5000]\ttraining's rmse: 3.58734\tvalid_1's rmse: 3.64735\n",
      "[6000]\ttraining's rmse: 3.57868\tvalid_1's rmse: 3.64522\n",
      "[7000]\ttraining's rmse: 3.57164\tvalid_1's rmse: 3.64392\n",
      "[8000]\ttraining's rmse: 3.56478\tvalid_1's rmse: 3.64324\n",
      "[9000]\ttraining's rmse: 3.55838\tvalid_1's rmse: 3.643\n",
      "[10000]\ttraining's rmse: 3.55206\tvalid_1's rmse: 3.64283\n",
      "[11000]\ttraining's rmse: 3.5463\tvalid_1's rmse: 3.64291\n",
      "Early stopping, best iteration is:\n",
      "[10253]\ttraining's rmse: 3.55049\tvalid_1's rmse: 3.6428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.6503367743055093"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param1 = {\n",
    "    'feature_fraction': 0.5775349282300533, \n",
    "    'max_depth': 6,\n",
    "    'min_data_in_leaf': 350,\n",
    "    'num_leaves': 243,\n",
    "    'reg_alpha': 0.08335604635874802,\n",
    "    \"metric\": 'rmse',  \n",
    "    \"boosting\": \"gbdt\",\n",
    "    'objective':'regression',\n",
    "    'learning_rate': 0.001,\n",
    "    'reg_lambda': 0.14749148707496232\n",
    "}\n",
    "\n",
    "folds = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "oof = np.zeros(x_train.shape[0])\n",
    "predictions = np.zeros(x_test.shape[0])\n",
    "feature_importance_df = pd.DataFrame()\n",
    "outlier = np.array([1 if i<-30 else 0 for i in y_train])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(x_train, outlier)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(x_train[trn_idx], label=y_train[trn_idx])\n",
    "    val_data = lgb.Dataset(x_train[val_idx], label=y_train[val_idx])\n",
    "\n",
    "    num_round = 30000\n",
    "    clf = lgb.train(param1, \n",
    "                    trn_data,\n",
    "                    num_round, \n",
    "                    valid_sets = [trn_data, val_data],\n",
    "                    verbose_eval=1000,\n",
    "                    early_stopping_rounds = 1000)\n",
    "    \n",
    "    oof[val_idx] = clf.predict(x_train[val_idx], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = feature_col\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(x_test, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "np.sqrt(mean_squared_error(oof, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 57.1min finished\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'feature_fraction': [0.5775349282300533], \n",
    "    'max_depth': [6],\n",
    "    'min_data_in_leaf': [350],\n",
    "    'num_leaves': [243],\n",
    "    'reg_alpha': [0.08335604635874802],\n",
    "    'learning_rate': [0.001],\n",
    "    'reg_lambda': [0.14749148707496232],\n",
    "    'num_iterations':[20000]\n",
    "}\n",
    "lgb_model1 = lgb.LGBMRegressor(objective='regression',\n",
    "                              min_data_in_leaf=20,\n",
    "                              num_leaves=50,\n",
    "                              num_iterations=100,\n",
    "                              learning_rate=0.1, \n",
    "                              max_depth=8,\n",
    "                              num_threads=8,\n",
    "                              feature_fraction = 0.8)\n",
    "\n",
    "gsearch11 = GridSearchCV(estimator=lgb_model1, \n",
    "                        param_grid=param,\n",
    "                        scoring='neg_mean_squared_error', \n",
    "                        cv=10,\n",
    "                        verbose=1, \n",
    "                        n_jobs=1)\n",
    "\n",
    "gs11 = gsearch11.fit(df_train[df_train_columns], df_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = gs11.predict(df_test[df_train_columns].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'card_id':df_test.card_id, 'target': y_test})\n",
    "submission.to_csv('/root/tempfile/moban_sklean10.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_columns = [c for c in df_train.columns if c not in ['card_id', 'first_active_month','target','outliers']]\n",
    "target = df_train['target']\n",
    "del df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.6627\tvalid_1's rmse: 3.73334\n",
      "[200]\ttraining's rmse: 3.58448\tvalid_1's rmse: 3.70258\n",
      "[300]\ttraining's rmse: 3.53791\tvalid_1's rmse: 3.68952\n",
      "[400]\ttraining's rmse: 3.502\tvalid_1's rmse: 3.68205\n",
      "[500]\ttraining's rmse: 3.47195\tvalid_1's rmse: 3.67658\n",
      "[600]\ttraining's rmse: 3.44625\tvalid_1's rmse: 3.67335\n",
      "[700]\ttraining's rmse: 3.42374\tvalid_1's rmse: 3.67124\n",
      "[800]\ttraining's rmse: 3.40368\tvalid_1's rmse: 3.66988\n",
      "[900]\ttraining's rmse: 3.38548\tvalid_1's rmse: 3.66849\n",
      "[1000]\ttraining's rmse: 3.36909\tvalid_1's rmse: 3.66806\n",
      "[1100]\ttraining's rmse: 3.35212\tvalid_1's rmse: 3.6684\n",
      "Early stopping, best iteration is:\n",
      "[1026]\ttraining's rmse: 3.36479\tvalid_1's rmse: 3.66783\n",
      "fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.67146\tvalid_1's rmse: 3.70281\n",
      "[200]\ttraining's rmse: 3.59637\tvalid_1's rmse: 3.66845\n",
      "[300]\ttraining's rmse: 3.55039\tvalid_1's rmse: 3.65472\n",
      "[400]\ttraining's rmse: 3.51441\tvalid_1's rmse: 3.64518\n",
      "[500]\ttraining's rmse: 3.48604\tvalid_1's rmse: 3.64038\n",
      "[600]\ttraining's rmse: 3.46113\tvalid_1's rmse: 3.63747\n",
      "[700]\ttraining's rmse: 3.43958\tvalid_1's rmse: 3.63518\n",
      "[800]\ttraining's rmse: 3.41876\tvalid_1's rmse: 3.634\n",
      "[900]\ttraining's rmse: 3.3997\tvalid_1's rmse: 3.63278\n",
      "[1000]\ttraining's rmse: 3.38225\tvalid_1's rmse: 3.63194\n",
      "[1100]\ttraining's rmse: 3.36549\tvalid_1's rmse: 3.63099\n",
      "[1200]\ttraining's rmse: 3.35035\tvalid_1's rmse: 3.63036\n",
      "[1300]\ttraining's rmse: 3.33524\tvalid_1's rmse: 3.63015\n",
      "[1400]\ttraining's rmse: 3.31959\tvalid_1's rmse: 3.63013\n",
      "Early stopping, best iteration is:\n",
      "[1349]\ttraining's rmse: 3.32761\tvalid_1's rmse: 3.62985\n",
      "fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.66269\tvalid_1's rmse: 3.72316\n",
      "[200]\ttraining's rmse: 3.58464\tvalid_1's rmse: 3.69278\n",
      "[300]\ttraining's rmse: 3.53766\tvalid_1's rmse: 3.68134\n",
      "[400]\ttraining's rmse: 3.50229\tvalid_1's rmse: 3.6747\n",
      "[500]\ttraining's rmse: 3.47281\tvalid_1's rmse: 3.66928\n",
      "[600]\ttraining's rmse: 3.44899\tvalid_1's rmse: 3.66656\n",
      "[700]\ttraining's rmse: 3.42559\tvalid_1's rmse: 3.66497\n",
      "[800]\ttraining's rmse: 3.40387\tvalid_1's rmse: 3.66431\n",
      "[900]\ttraining's rmse: 3.38452\tvalid_1's rmse: 3.66379\n",
      "[1000]\ttraining's rmse: 3.36634\tvalid_1's rmse: 3.66346\n",
      "[1100]\ttraining's rmse: 3.34861\tvalid_1's rmse: 3.66293\n",
      "Early stopping, best iteration is:\n",
      "[1097]\ttraining's rmse: 3.34917\tvalid_1's rmse: 3.66286\n",
      "fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.66725\tvalid_1's rmse: 3.71526\n",
      "[200]\ttraining's rmse: 3.58963\tvalid_1's rmse: 3.68457\n",
      "[300]\ttraining's rmse: 3.54244\tvalid_1's rmse: 3.67161\n",
      "[400]\ttraining's rmse: 3.50703\tvalid_1's rmse: 3.6651\n",
      "[500]\ttraining's rmse: 3.47794\tvalid_1's rmse: 3.66091\n",
      "[600]\ttraining's rmse: 3.45216\tvalid_1's rmse: 3.65852\n",
      "[700]\ttraining's rmse: 3.42968\tvalid_1's rmse: 3.65663\n",
      "[800]\ttraining's rmse: 3.40905\tvalid_1's rmse: 3.65596\n",
      "[900]\ttraining's rmse: 3.39097\tvalid_1's rmse: 3.65536\n",
      "[1000]\ttraining's rmse: 3.37333\tvalid_1's rmse: 3.65488\n",
      "[1100]\ttraining's rmse: 3.3565\tvalid_1's rmse: 3.65443\n",
      "[1200]\ttraining's rmse: 3.34069\tvalid_1's rmse: 3.65426\n",
      "[1300]\ttraining's rmse: 3.32573\tvalid_1's rmse: 3.65414\n",
      "[1400]\ttraining's rmse: 3.31173\tvalid_1's rmse: 3.65421\n",
      "Early stopping, best iteration is:\n",
      "[1341]\ttraining's rmse: 3.31992\tvalid_1's rmse: 3.65385\n",
      "fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.66542\tvalid_1's rmse: 3.71117\n",
      "[200]\ttraining's rmse: 3.5872\tvalid_1's rmse: 3.68351\n",
      "[300]\ttraining's rmse: 3.53965\tvalid_1's rmse: 3.67181\n",
      "[400]\ttraining's rmse: 3.50267\tvalid_1's rmse: 3.66522\n",
      "[500]\ttraining's rmse: 3.47277\tvalid_1's rmse: 3.66168\n",
      "[600]\ttraining's rmse: 3.44665\tvalid_1's rmse: 3.65891\n",
      "[700]\ttraining's rmse: 3.42475\tvalid_1's rmse: 3.65754\n",
      "[800]\ttraining's rmse: 3.40384\tvalid_1's rmse: 3.65721\n",
      "[900]\ttraining's rmse: 3.38484\tvalid_1's rmse: 3.65704\n",
      "[1000]\ttraining's rmse: 3.36729\tvalid_1's rmse: 3.65613\n",
      "[1100]\ttraining's rmse: 3.35093\tvalid_1's rmse: 3.65562\n",
      "[1200]\ttraining's rmse: 3.3353\tvalid_1's rmse: 3.65547\n",
      "Early stopping, best iteration is:\n",
      "[1116]\ttraining's rmse: 3.34836\tvalid_1's rmse: 3.65531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.6539629368389783"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": 4}\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "oof = np.zeros(len(df_train))\n",
    "predictions = np.zeros(len(df_test))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train,df_train['outliers'].values)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(df_train.iloc[trn_idx][df_train_columns], label=target.iloc[trn_idx])#, categorical_feature=categorical_feats)\n",
    "    val_data = lgb.Dataset(df_train.iloc[val_idx][df_train_columns], label=target.iloc[val_idx])#, categorical_feature=categorical_feats)\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 100)\n",
    "    oof[val_idx] = clf.predict(df_train.iloc[val_idx][df_train_columns], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = df_train_columns\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(df_test[df_train_columns], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "np.sqrt(mean_squared_error(oof, target))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'card_id':testindex, 'target':predictions})\n",
    "submission.to_csv('/root/tempfile/submission19121633.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
