{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, StratifiedKFold, cross_val_score\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/root/tempfile/train_final191219.csv')\n",
    "df_test = pd.read_csv('/root/tempfile/test_final191219.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201917, 106) (123623, 104)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_col = [x for x in train_df.columns if x not in ['card_id','target', 'outliers']]\n",
    "y_train = train_df.target.values.astype('float')\n",
    "x_train = train_df[feature_col].values.astype('float')\n",
    "x_test = test_df[feature_col].values.astype('float')\n",
    "\n",
    "testindex = test_df.card_id\n",
    "del train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_cv(param, data, cv):\n",
    "    score = lgb.cv( \n",
    "        param, \n",
    "        data, \n",
    "        nfold=cv,\n",
    "        stratified=False, \n",
    "        shuffle=True,\n",
    "        metrics='rmse',\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False, \n",
    "        show_stdv=False)\n",
    "    return score['rmse-mean'][-1]\n",
    "\n",
    "\n",
    "def hyperopt_train_test(params):\n",
    "    global df_train\n",
    "    \n",
    "    param = {\n",
    "        'objective':'regression',\n",
    "        \"boosting\": \"gbdt\",\n",
    "    }\n",
    "    param['max_depth'] = int(params['max_depth'])\n",
    "    param['num_leaves'] = int(params['num_leaves'])\n",
    "    param['min_data_in_leaf'] = int(params['min_data_in_leaf'])\n",
    "    param['reg_alpha'] = params['reg_alpha']\n",
    "    param['reg_lambda'] = params['reg_lambda']\n",
    "    param['feature_fraction'] = params['feature_fraction']\n",
    "    \n",
    "    df_train_columns = [c for c in df_train.columns if c not in ['card_id', 'target', 'outliers']]\n",
    "    data_train = lgb.Dataset(df_train[df_train_columns], label=df_train['target'])\n",
    "    return regression_cv(param, data_train, cv=5)\n",
    "\n",
    "\n",
    "def f(params):\n",
    "    global best\n",
    "    score = hyperopt_train_test(params)\n",
    "    if -score > best:\n",
    "        best = -score\n",
    "        print('new best:', -best, params)\n",
    "    return {'loss': score, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best: 3.6594868902423285 {'feature_fraction': 0.7605399640104678, 'max_depth': 10.0, 'min_data_in_leaf': 338.0, 'num_leaves': 261.0, 'reg_alpha': 0.403447762002815, 'reg_lambda': 0.12244910687623989}\n",
      "new best: 3.658996037508916 {'feature_fraction': 0.5503257516017639, 'max_depth': 8.0, 'min_data_in_leaf': 300.0, 'num_leaves': 131.0, 'reg_alpha': 0.12082629332374684, 'reg_lambda': 0.07921996170038431}\n",
      "new best: 3.658954082970829 {'feature_fraction': 0.9033794260256631, 'max_depth': 7.0, 'min_data_in_leaf': 313.0, 'num_leaves': 265.0, 'reg_alpha': 0.35132753980099646, 'reg_lambda': 0.33651085966405847}\n",
      "new best: 3.6580084602033778 {'feature_fraction': 0.6229566400813662, 'max_depth': 6.0, 'min_data_in_leaf': 323.0, 'num_leaves': 115.0, 'reg_alpha': 0.44268090060991155, 'reg_lambda': 0.48822790474864886}\n",
      "new best: 3.656348666880306 {'feature_fraction': 0.8408479610383566, 'max_depth': 5.0, 'min_data_in_leaf': 259.0, 'num_leaves': 45.0, 'reg_alpha': 0.4950366827340328, 'reg_lambda': 0.4016350014191029}\n",
      "new best: 3.6554709830961314 {'feature_fraction': 0.7651354528161662, 'max_depth': 7.0, 'min_data_in_leaf': 326.0, 'num_leaves': 122.0, 'reg_alpha': 0.449871791959349, 'reg_lambda': 0.011076558942712728}\n",
      "new best: 3.6550769770590654 {'feature_fraction': 0.7867937941239228, 'max_depth': 7.0, 'min_data_in_leaf': 318.0, 'num_leaves': 146.0, 'reg_alpha': 0.25539610858734724, 'reg_lambda': 0.07250331234733394}\n",
      "new best: 3.6545892640700393 {'feature_fraction': 0.8609490852544645, 'max_depth': 6.0, 'min_data_in_leaf': 323.0, 'num_leaves': 240.0, 'reg_alpha': 0.28727372600327195, 'reg_lambda': 0.02607489242405017}\n",
      "best:\n",
      "{'feature_fraction': 0.8609490852544645, 'max_depth': 6.0, 'min_data_in_leaf': 323.0, 'num_leaves': 240.0, 'reg_alpha': 0.28727372600327195, 'reg_lambda': 0.02607489242405017}\n"
     ]
    }
   ],
   "source": [
    "space4rf = {\n",
    "    'max_depth': hp.quniform('max_depth', 5, 13, 1),\n",
    "    'num_leaves':hp.quniform('num_leaves', 10, 350, 1),\n",
    "    'min_data_in_leaf':hp.quniform('min_data_in_leaf', 10, 350, 1),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0, 0.5),   \n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0, 0.5),\n",
    "    'feature_fraction' : hp.uniform('feature_fraction', 0.5, 1)}\n",
    "\n",
    "best = -15\n",
    "trials = Trials()\n",
    "best = fmin(f, space4rf, algo=tpe.suggest, max_evals=1000, trials=trials)\n",
    "\n",
    "print('best:')\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'learning_rate':0.001,\n",
    "    'objective':'regression',\n",
    "    'metric':'rmse'\n",
    "}\n",
    "param = dict(param, **best)\n",
    "param['max_depth'] = int(param['max_depth'])\n",
    "param['min_data_in_leaf'] = int(param['min_data_in_leaf'])\n",
    "param['num_leaves'] = int(param['num_leaves'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's rmse: 3.69336\tvalid_1's rmse: 3.70142\n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "oof = np.zeros(len(df_train))\n",
    "predictions = np.zeros(len(df_test))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "df_train_columns = [c for c in df_train.columns if c not in ['card_id', 'target', 'outliers']]\n",
    "\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train,df_train['outliers'].values)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(df_train.iloc[trn_idx][df_train_columns], label=df_train['target'][trn_idx])#, categorical_feature=categorical_feats)\n",
    "    val_data = lgb.Dataset(df_train.iloc[val_idx][df_train_columns], label=df_train['target'][val_idx])#, categorical_feature=categorical_feats)\n",
    "\n",
    "    num_round = 20000\n",
    "    clf = lgb.train(param,\n",
    "                    trn_data,\n",
    "                    num_round, \n",
    "                    valid_sets = [trn_data, val_data], \n",
    "                    verbose_eval=1000,\n",
    "                    early_stopping_rounds = 1000)\n",
    "    oof[val_idx] = clf.predict(df_train.iloc[val_idx][df_train_columns], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = df_train_columns\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(df_test[df_train_columns], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "np.sqrt(mean_squared_error(oof, df_train['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's rmse: 3.69053\tvalid_1's rmse: 3.709\n",
      "[2000]\ttraining's rmse: 3.64098\tvalid_1's rmse: 3.67331\n",
      "[3000]\ttraining's rmse: 3.617\tvalid_1's rmse: 3.66117\n",
      "[4000]\ttraining's rmse: 3.60202\tvalid_1's rmse: 3.65514\n",
      "[5000]\ttraining's rmse: 3.59109\tvalid_1's rmse: 3.65182\n",
      "[6000]\ttraining's rmse: 3.58142\tvalid_1's rmse: 3.64919\n",
      "[7000]\ttraining's rmse: 3.57311\tvalid_1's rmse: 3.64752\n",
      "[8000]\ttraining's rmse: 3.5666\tvalid_1's rmse: 3.64635\n",
      "[9000]\ttraining's rmse: 3.56016\tvalid_1's rmse: 3.64537\n",
      "[10000]\ttraining's rmse: 3.55399\tvalid_1's rmse: 3.64458\n",
      "[11000]\ttraining's rmse: 3.54782\tvalid_1's rmse: 3.64428\n",
      "[12000]\ttraining's rmse: 3.54201\tvalid_1's rmse: 3.64403\n",
      "[13000]\ttraining's rmse: 3.53626\tvalid_1's rmse: 3.64375\n",
      "[14000]\ttraining's rmse: 3.53074\tvalid_1's rmse: 3.6434\n",
      "[15000]\ttraining's rmse: 3.5252\tvalid_1's rmse: 3.64322\n",
      "[16000]\ttraining's rmse: 3.51948\tvalid_1's rmse: 3.64308\n",
      "[17000]\ttraining's rmse: 3.51377\tvalid_1's rmse: 3.64302\n",
      "Early stopping, best iteration is:\n",
      "[16621]\ttraining's rmse: 3.5159\tvalid_1's rmse: 3.64295\n",
      "fold 1\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's rmse: 3.69075\tvalid_1's rmse: 3.71219\n",
      "[2000]\ttraining's rmse: 3.6403\tvalid_1's rmse: 3.6832\n",
      "[3000]\ttraining's rmse: 3.61504\tvalid_1's rmse: 3.67433\n",
      "[4000]\ttraining's rmse: 3.59932\tvalid_1's rmse: 3.67129\n",
      "[5000]\ttraining's rmse: 3.58858\tvalid_1's rmse: 3.66958\n",
      "[6000]\ttraining's rmse: 3.57949\tvalid_1's rmse: 3.6685\n",
      "[7000]\ttraining's rmse: 3.57157\tvalid_1's rmse: 3.66766\n",
      "[8000]\ttraining's rmse: 3.56429\tvalid_1's rmse: 3.6672\n",
      "[9000]\ttraining's rmse: 3.55747\tvalid_1's rmse: 3.667\n",
      "[10000]\ttraining's rmse: 3.5514\tvalid_1's rmse: 3.66694\n",
      "Early stopping, best iteration is:\n",
      "[9794]\ttraining's rmse: 3.55258\tvalid_1's rmse: 3.66689\n",
      "fold 2\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's rmse: 3.691\tvalid_1's rmse: 3.70613\n",
      "[2000]\ttraining's rmse: 3.64243\tvalid_1's rmse: 3.67222\n",
      "[3000]\ttraining's rmse: 3.61817\tvalid_1's rmse: 3.66018\n",
      "[4000]\ttraining's rmse: 3.6029\tvalid_1's rmse: 3.6548\n",
      "[5000]\ttraining's rmse: 3.5924\tvalid_1's rmse: 3.65077\n",
      "[6000]\ttraining's rmse: 3.58406\tvalid_1's rmse: 3.64833\n",
      "[7000]\ttraining's rmse: 3.57717\tvalid_1's rmse: 3.64662\n",
      "[8000]\ttraining's rmse: 3.57073\tvalid_1's rmse: 3.64483\n",
      "[9000]\ttraining's rmse: 3.56437\tvalid_1's rmse: 3.64377\n",
      "[10000]\ttraining's rmse: 3.55829\tvalid_1's rmse: 3.64294\n",
      "[11000]\ttraining's rmse: 3.55191\tvalid_1's rmse: 3.6425\n",
      "[12000]\ttraining's rmse: 3.54596\tvalid_1's rmse: 3.64192\n",
      "[13000]\ttraining's rmse: 3.53985\tvalid_1's rmse: 3.6412\n",
      "[14000]\ttraining's rmse: 3.53408\tvalid_1's rmse: 3.64063\n",
      "[15000]\ttraining's rmse: 3.52858\tvalid_1's rmse: 3.64014\n",
      "[16000]\ttraining's rmse: 3.52305\tvalid_1's rmse: 3.63957\n",
      "[17000]\ttraining's rmse: 3.51758\tvalid_1's rmse: 3.63932\n",
      "[18000]\ttraining's rmse: 3.51237\tvalid_1's rmse: 3.63908\n",
      "[19000]\ttraining's rmse: 3.50729\tvalid_1's rmse: 3.6389\n",
      "[20000]\ttraining's rmse: 3.50232\tvalid_1's rmse: 3.63859\n",
      "[21000]\ttraining's rmse: 3.49714\tvalid_1's rmse: 3.63855\n",
      "[22000]\ttraining's rmse: 3.49215\tvalid_1's rmse: 3.63858\n",
      "Early stopping, best iteration is:\n",
      "[21346]\ttraining's rmse: 3.49538\tvalid_1's rmse: 3.63851\n",
      "fold 3\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's rmse: 3.69059\tvalid_1's rmse: 3.71102\n",
      "[2000]\ttraining's rmse: 3.64193\tvalid_1's rmse: 3.67361\n",
      "[3000]\ttraining's rmse: 3.61664\tvalid_1's rmse: 3.65937\n",
      "[4000]\ttraining's rmse: 3.60171\tvalid_1's rmse: 3.65366\n",
      "[5000]\ttraining's rmse: 3.5911\tvalid_1's rmse: 3.65053\n",
      "[6000]\ttraining's rmse: 3.58258\tvalid_1's rmse: 3.6491\n",
      "[7000]\ttraining's rmse: 3.57484\tvalid_1's rmse: 3.64852\n",
      "[8000]\ttraining's rmse: 3.56829\tvalid_1's rmse: 3.64839\n",
      "[9000]\ttraining's rmse: 3.56206\tvalid_1's rmse: 3.64811\n",
      "[10000]\ttraining's rmse: 3.55604\tvalid_1's rmse: 3.64797\n",
      "[11000]\ttraining's rmse: 3.55024\tvalid_1's rmse: 3.64771\n",
      "[12000]\ttraining's rmse: 3.54468\tvalid_1's rmse: 3.64754\n",
      "[13000]\ttraining's rmse: 3.53924\tvalid_1's rmse: 3.64757\n",
      "Early stopping, best iteration is:\n",
      "[12555]\ttraining's rmse: 3.54159\tvalid_1's rmse: 3.64749\n",
      "fold 4\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's rmse: 3.69063\tvalid_1's rmse: 3.70425\n",
      "[2000]\ttraining's rmse: 3.64139\tvalid_1's rmse: 3.67096\n",
      "[3000]\ttraining's rmse: 3.61677\tvalid_1's rmse: 3.66036\n",
      "[4000]\ttraining's rmse: 3.60183\tvalid_1's rmse: 3.65555\n",
      "[5000]\ttraining's rmse: 3.59132\tvalid_1's rmse: 3.65273\n",
      "[6000]\ttraining's rmse: 3.58296\tvalid_1's rmse: 3.65103\n",
      "[7000]\ttraining's rmse: 3.57548\tvalid_1's rmse: 3.65006\n",
      "[8000]\ttraining's rmse: 3.56884\tvalid_1's rmse: 3.64935\n",
      "[9000]\ttraining's rmse: 3.56268\tvalid_1's rmse: 3.64885\n",
      "[10000]\ttraining's rmse: 3.5567\tvalid_1's rmse: 3.64859\n",
      "[11000]\ttraining's rmse: 3.55095\tvalid_1's rmse: 3.64823\n",
      "[12000]\ttraining's rmse: 3.5454\tvalid_1's rmse: 3.64801\n",
      "[13000]\ttraining's rmse: 3.53991\tvalid_1's rmse: 3.64768\n",
      "[14000]\ttraining's rmse: 3.53467\tvalid_1's rmse: 3.64735\n",
      "[15000]\ttraining's rmse: 3.52884\tvalid_1's rmse: 3.64704\n",
      "[16000]\ttraining's rmse: 3.52367\tvalid_1's rmse: 3.64687\n",
      "[17000]\ttraining's rmse: 3.51847\tvalid_1's rmse: 3.64664\n",
      "[18000]\ttraining's rmse: 3.51387\tvalid_1's rmse: 3.6464\n",
      "[19000]\ttraining's rmse: 3.50908\tvalid_1's rmse: 3.64618\n",
      "[20000]\ttraining's rmse: 3.5041\tvalid_1's rmse: 3.64596\n",
      "[21000]\ttraining's rmse: 3.49945\tvalid_1's rmse: 3.64583\n",
      "[22000]\ttraining's rmse: 3.49479\tvalid_1's rmse: 3.64569\n",
      "[23000]\ttraining's rmse: 3.49011\tvalid_1's rmse: 3.64573\n",
      "Early stopping, best iteration is:\n",
      "[22433]\ttraining's rmse: 3.49279\tvalid_1's rmse: 3.64564\n",
      "fold 5\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's rmse: 3.68785\tvalid_1's rmse: 3.73382\n",
      "[2000]\ttraining's rmse: 3.63803\tvalid_1's rmse: 3.70037\n",
      "[3000]\ttraining's rmse: 3.61322\tvalid_1's rmse: 3.6866\n",
      "[4000]\ttraining's rmse: 3.5984\tvalid_1's rmse: 3.68077\n",
      "[5000]\ttraining's rmse: 3.58754\tvalid_1's rmse: 3.67706\n",
      "[6000]\ttraining's rmse: 3.57911\tvalid_1's rmse: 3.67477\n",
      "[7000]\ttraining's rmse: 3.57196\tvalid_1's rmse: 3.67323\n",
      "[8000]\ttraining's rmse: 3.56521\tvalid_1's rmse: 3.67207\n",
      "[9000]\ttraining's rmse: 3.5588\tvalid_1's rmse: 3.67122\n",
      "[10000]\ttraining's rmse: 3.55285\tvalid_1's rmse: 3.67047\n",
      "[11000]\ttraining's rmse: 3.54739\tvalid_1's rmse: 3.66984\n",
      "[12000]\ttraining's rmse: 3.54233\tvalid_1's rmse: 3.66964\n",
      "[13000]\ttraining's rmse: 3.53714\tvalid_1's rmse: 3.6695\n",
      "[14000]\ttraining's rmse: 3.53157\tvalid_1's rmse: 3.66931\n",
      "[15000]\ttraining's rmse: 3.52605\tvalid_1's rmse: 3.66934\n",
      "Early stopping, best iteration is:\n",
      "[14235]\ttraining's rmse: 3.53031\tvalid_1's rmse: 3.66929\n",
      "fold 6\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's rmse: 3.69244\tvalid_1's rmse: 3.70732\n",
      "[2000]\ttraining's rmse: 3.64436\tvalid_1's rmse: 3.66901\n",
      "[3000]\ttraining's rmse: 3.62047\tvalid_1's rmse: 3.65325\n",
      "[4000]\ttraining's rmse: 3.60556\tvalid_1's rmse: 3.64405\n",
      "[5000]\ttraining's rmse: 3.59511\tvalid_1's rmse: 3.6389\n",
      "[6000]\ttraining's rmse: 3.58623\tvalid_1's rmse: 3.63523\n",
      "[7000]\ttraining's rmse: 3.5783\tvalid_1's rmse: 3.63222\n",
      "[8000]\ttraining's rmse: 3.57098\tvalid_1's rmse: 3.6302\n",
      "[9000]\ttraining's rmse: 3.5643\tvalid_1's rmse: 3.62855\n",
      "[10000]\ttraining's rmse: 3.55794\tvalid_1's rmse: 3.62739\n",
      "[11000]\ttraining's rmse: 3.55193\tvalid_1's rmse: 3.62654\n",
      "[12000]\ttraining's rmse: 3.54628\tvalid_1's rmse: 3.62596\n",
      "[13000]\ttraining's rmse: 3.54086\tvalid_1's rmse: 3.62557\n",
      "[14000]\ttraining's rmse: 3.5353\tvalid_1's rmse: 3.62525\n",
      "[15000]\ttraining's rmse: 3.53037\tvalid_1's rmse: 3.62518\n",
      "[16000]\ttraining's rmse: 3.52506\tvalid_1's rmse: 3.6252\n",
      "Early stopping, best iteration is:\n",
      "[15473]\ttraining's rmse: 3.52793\tvalid_1's rmse: 3.6251\n",
      "fold 7\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's rmse: 3.69113\tvalid_1's rmse: 3.70654\n",
      "[2000]\ttraining's rmse: 3.64123\tvalid_1's rmse: 3.67403\n",
      "[3000]\ttraining's rmse: 3.6163\tvalid_1's rmse: 3.66378\n",
      "[4000]\ttraining's rmse: 3.60069\tvalid_1's rmse: 3.65908\n",
      "[5000]\ttraining's rmse: 3.58921\tvalid_1's rmse: 3.65658\n",
      "[6000]\ttraining's rmse: 3.57978\tvalid_1's rmse: 3.65472\n",
      "[7000]\ttraining's rmse: 3.57176\tvalid_1's rmse: 3.65385\n",
      "[8000]\ttraining's rmse: 3.56445\tvalid_1's rmse: 3.65332\n",
      "[9000]\ttraining's rmse: 3.55786\tvalid_1's rmse: 3.653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10000]\ttraining's rmse: 3.55243\tvalid_1's rmse: 3.65295\n",
      "Early stopping, best iteration is:\n",
      "[9956]\ttraining's rmse: 3.55267\tvalid_1's rmse: 3.65293\n",
      "fold 8\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's rmse: 3.69088\tvalid_1's rmse: 3.70659\n",
      "[2000]\ttraining's rmse: 3.64153\tvalid_1's rmse: 3.6747\n",
      "[3000]\ttraining's rmse: 3.61715\tvalid_1's rmse: 3.66165\n",
      "[4000]\ttraining's rmse: 3.6019\tvalid_1's rmse: 3.65503\n",
      "[5000]\ttraining's rmse: 3.5906\tvalid_1's rmse: 3.65059\n",
      "[6000]\ttraining's rmse: 3.58155\tvalid_1's rmse: 3.64828\n",
      "[7000]\ttraining's rmse: 3.57372\tvalid_1's rmse: 3.64691\n",
      "[8000]\ttraining's rmse: 3.56668\tvalid_1's rmse: 3.64619\n",
      "[9000]\ttraining's rmse: 3.5602\tvalid_1's rmse: 3.6457\n",
      "[10000]\ttraining's rmse: 3.55395\tvalid_1's rmse: 3.64538\n",
      "[11000]\ttraining's rmse: 3.54776\tvalid_1's rmse: 3.64513\n",
      "[12000]\ttraining's rmse: 3.54172\tvalid_1's rmse: 3.64479\n",
      "[13000]\ttraining's rmse: 3.53577\tvalid_1's rmse: 3.64457\n",
      "[14000]\ttraining's rmse: 3.53034\tvalid_1's rmse: 3.64426\n",
      "[15000]\ttraining's rmse: 3.52505\tvalid_1's rmse: 3.64418\n",
      "[16000]\ttraining's rmse: 3.51982\tvalid_1's rmse: 3.64397\n",
      "[17000]\ttraining's rmse: 3.5146\tvalid_1's rmse: 3.64381\n",
      "[18000]\ttraining's rmse: 3.50902\tvalid_1's rmse: 3.64373\n",
      "[19000]\ttraining's rmse: 3.50367\tvalid_1's rmse: 3.64374\n",
      "Early stopping, best iteration is:\n",
      "[18103]\ttraining's rmse: 3.50853\tvalid_1's rmse: 3.64368\n",
      "fold 9\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[1000]\ttraining's rmse: 3.69073\tvalid_1's rmse: 3.70607\n",
      "[2000]\ttraining's rmse: 3.64059\tvalid_1's rmse: 3.68003\n",
      "[3000]\ttraining's rmse: 3.61588\tvalid_1's rmse: 3.67202\n",
      "[4000]\ttraining's rmse: 3.60084\tvalid_1's rmse: 3.66974\n",
      "[5000]\ttraining's rmse: 3.58941\tvalid_1's rmse: 3.66777\n",
      "[6000]\ttraining's rmse: 3.58081\tvalid_1's rmse: 3.66649\n",
      "[7000]\ttraining's rmse: 3.57278\tvalid_1's rmse: 3.66555\n",
      "[8000]\ttraining's rmse: 3.56551\tvalid_1's rmse: 3.66498\n",
      "[9000]\ttraining's rmse: 3.55865\tvalid_1's rmse: 3.66475\n",
      "Early stopping, best iteration is:\n",
      "[8668]\ttraining's rmse: 3.56076\tvalid_1's rmse: 3.66472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.6497440733794266"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "oof = np.zeros(x_train.shape[0])\n",
    "predictions = np.zeros(x_test.shape[0])\n",
    "feature_importance_df = pd.DataFrame()\n",
    "outlier = np.array([1 if i<-30 else 0 for i in y_train])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(x_train, outlier)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(x_train[trn_idx], label=y_train[trn_idx])\n",
    "    val_data = lgb.Dataset(x_train[val_idx], label=y_train[val_idx])\n",
    "\n",
    "    num_round = 30000\n",
    "    clf = lgb.train(param, \n",
    "                    trn_data,\n",
    "                    num_round, \n",
    "                    valid_sets = [trn_data, val_data],\n",
    "                    verbose_eval=1000,\n",
    "                    early_stopping_rounds = 1000)\n",
    "    \n",
    "    oof[val_idx] = clf.predict(x_train[val_idx], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = feature_col\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(x_test, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "np.sqrt(mean_squared_error(oof, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123623, 103)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'card_id':testindex, 'target':predictions})\n",
    "submission.to_csv('/root/tempfile/submissioncv10.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/root/anaconda3/envs/jupyter/lib/python3.7/site-packages/lightgbm/engine.py:113: UserWarning: Found `num_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/root/anaconda3/envs/jupyter/lib/python3.7/site-packages/lightgbm/engine.py:113: UserWarning: Found `num_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/root/anaconda3/envs/jupyter/lib/python3.7/site-packages/lightgbm/engine.py:113: UserWarning: Found `num_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/root/anaconda3/envs/jupyter/lib/python3.7/site-packages/lightgbm/engine.py:113: UserWarning: Found `num_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/root/anaconda3/envs/jupyter/lib/python3.7/site-packages/lightgbm/engine.py:113: UserWarning: Found `num_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 34.5min finished\n",
      "/root/anaconda3/envs/jupyter/lib/python3.7/site-packages/lightgbm/engine.py:113: UserWarning: Found `num_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'feature_fraction': [0.7507665568504719],\n",
    "    'max_depth': [6],\n",
    "    'min_data_in_leaf': [327],\n",
    "    'num_leaves': [221],\n",
    "    'reg_alpha': [0.2990535105829924],\n",
    "    'reg_lambda': [0.27807440463243627],\n",
    "}\n",
    "\n",
    "lgb_model1 = lgb.LGBMRegressor(objective='regression',\n",
    "                              min_data_in_leaf=20,\n",
    "                              num_leaves=50,\n",
    "                              num_round=20000,\n",
    "                              learning_rate=0.001, \n",
    "                              max_depth=8,\n",
    "                              bagging_fraction = 0.8,\n",
    "                              feature_fraction = 0.8,\n",
    "                               num_threads=8)\n",
    "\n",
    "gsearch11 = GridSearchCV(estimator=lgb_model1, \n",
    "                        param_grid=param,\n",
    "                        scoring='neg_mean_squared_error', \n",
    "                        cv=5,\n",
    "                        verbose=1, \n",
    "                        n_jobs=1)\n",
    "\n",
    "gs11 = gsearch11.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = gs11.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'card_id':testindex, 'target':predictions})\n",
    "submission.to_csv('/root/tempfile/submission19121633.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
